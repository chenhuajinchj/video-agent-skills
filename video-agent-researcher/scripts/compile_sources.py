#!/usr/bin/env python3
"""
ç´ ææ±‡æ€»å·¥å…·ã€‚
æ‰«æ materials ç›®å½•ï¼Œä¸ºæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆæ‘˜è¦ï¼Œæ±‡æ€»åˆ° sources.jsonã€‚
"""

import json
import sys
from pathlib import Path
from typing import List, Dict
from datetime import datetime


def scan_materials(materials_dir: str) -> List[Dict]:
    """æ‰«æç´ æç›®å½•ï¼Œæ”¶é›†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯ã€‚"""
    base = Path(materials_dir)
    sources = []
    idx = 1

    # æ‰«ææ–‡ç« 
    articles_dir = base / "articles"
    if articles_dir.exists():
        for f in sorted(articles_dir.glob("*.txt")):
            content = f.read_text(encoding="utf-8", errors="replace")
            summary = extract_summary(content)
            sources.append({
                "id": f"src_{idx:03d}",
                "type": "article",
                "title": extract_title_from_file(content, f.stem),
                "file": str(f),
                "summary": summary,
                "char_count": len(content)
            })
            idx += 1

    # æ‰«æå­—å¹•
    transcripts_dir = base / "transcripts"
    if transcripts_dir.exists():
        for f in sorted(transcripts_dir.glob("*.txt")):
            content = f.read_text(encoding="utf-8", errors="replace")
            summary = extract_summary(content)
            sources.append({
                "id": f"src_{idx:03d}",
                "type": "youtube",
                "title": extract_title_from_file(content, f.stem),
                "file": str(f),
                "summary": summary,
                "char_count": len(content)
            })
            idx += 1

    return sources


def extract_summary(content: str, max_chars: int = 200) -> str:
    """æå–æ–‡ä»¶å‰ 200 å­—ä½œä¸ºæ‘˜è¦ã€‚"""
    # è·³è¿‡å…ƒä¿¡æ¯å¤´éƒ¨ï¼ˆæ¥æºã€æ—¶é—´ç­‰ï¼‰
    lines = content.split("\n")
    text_lines = []
    skip_header = True
    for line in lines:
        if skip_header and (line.startswith("æ¥æº:") or line.startswith("è§†é¢‘æ ‡é¢˜:") or
                           line.startswith("æŠ“å–æ—¶é—´:") or line.startswith("ä¸‹è½½æ—¶é—´:") or
                           not line.strip()):
            continue
        skip_header = False
        text_lines.append(line.strip())

    text = " ".join(text_lines)
    if len(text) > max_chars:
        text = text[:max_chars] + "..."
    return text


def extract_title_from_file(content: str, fallback: str) -> str:
    """ä»æ–‡ä»¶å†…å®¹æå–æ ‡é¢˜ã€‚"""
    for line in content.split("\n"):
        line = line.strip()
        if line.startswith("è§†é¢‘æ ‡é¢˜:"):
            return line.replace("è§†é¢‘æ ‡é¢˜:", "").strip()
        if line and not line.startswith("æ¥æº:") and not line.startswith("æŠ“å–æ—¶é—´:"):
            return line[:80]
    return fallback


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python compile_sources.py <materials_dir> <topic>")
        print("ç¤ºä¾‹: python compile_sources.py ./materials 'è®¤çŸ¥åå·®'")
        sys.exit(1)

    materials_dir = sys.argv[1]
    topic = sys.argv[2]

    if not Path(materials_dir).exists():
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {materials_dir}")
        sys.exit(1)

    print(f"ğŸ” æ­£åœ¨æ‰«æç´ æç›®å½•: {materials_dir}")
    sources = scan_materials(materials_dir)

    if not sources:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç´ ææ–‡ä»¶")
        sys.exit(0)

    # æ±‡æ€»åˆ° sources.json
    result = {
        "topic": topic,
        "search_date": datetime.now().strftime("%Y-%m-%d"),
        "total_sources": len(sources),
        "sources": sources
    }

    output_path = Path(materials_dir) / "sources.json"
    output_path.write_text(json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")

    print(f"\nâœ… ç´ ææ±‡æ€»å®Œæˆ: {output_path}")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    articles = [s for s in sources if s["type"] == "article"]
    transcripts = [s for s in sources if s["type"] == "youtube"]
    print(f"   æ–‡ç« : {len(articles)} ç¯‡")
    print(f"   å­—å¹•: {len(transcripts)} ä¸ª")
    total_chars = sum(s["char_count"] for s in sources)
    print(f"   æ€»å­—æ•°: {total_chars}")


if __name__ == "__main__":
    main()
